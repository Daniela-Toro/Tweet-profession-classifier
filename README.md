# Tweet Profession Classifier üß†üá™üá∏

Este proyecto entrena un modelo de aprendizaje autom√°tico para **clasificar tweets en espa√±ol** seg√∫n si **mencionan o no una profesi√≥n**. Est√° dise√±ado para tareas de an√°lisis de contenido en redes sociales, miner√≠a de texto o estudios socioling√º√≠sticos.

> üîß Desarrollado √≠ntegramente en **Google Colaboratory**, utilizando Python y librer√≠as de NLP modernas como Hugging Face ü§ó Transformers.

---

## üìä Objetivo

Entrenar un modelo BERT en espa√±ol para clasificar tweets en dos clases:
- **Clase 0 (SIN_PROFESI√ìN)**: No menciona profesiones.
- **Clase 1 (CON_PROFESI√ìN)**: Menciona profesiones expl√≠citamente.

---

## üß™ M√©tricas del mejor modelo

| Clase                | Precisi√≥n | Recall | F1-Score |
|----------------------|-----------|--------|----------|
| **SIN_PROFESI√ìN (0)** | 0.98      | 0.94   | 0.96     |
| **CON_PROFESI√ìN (1)** | 0.83      | 0.95   | 0.89     |

> Accuracy total: **93.8%**  
> F1 macro promedio: **0.938**

---

## üßº Preprocesamiento

- Tokenizaci√≥n con HuggingFace `AutoTokenizer`

---

## üßæ Fuente de Datos

Utilizamos un subconjunto de datos provenientes de redes sociales, espec√≠ficamente de la tarea 1 del shared task [**ProfNER**](https://temu.bsc.es/smm4h-spanish), centrado en la detecci√≥n de menciones a profesiones en tweets publicados durante la pandemia del COVID-19.

El objetivo original de dicha tarea era analizar qu√© profesiones podr√≠an haber sido especialmente vulnerables en el contexto de la crisis sanitaria.

Descargamos los datos del [repositorio de Hugging Face](https://huggingface.co/datasets/luisgasco/profner_classification_master), en el que se incluyen:

- **Datos de entrenamiento**: con identificadores, texto y etiquetas.
- **Datos de validaci√≥n**: misma estructura que el conjunto de entrenamiento.
- **Datos de prueba (test)**: incluye identificadores y texto, pero **sin etiquetas**.

---

## ü§ñ Modelo

- Modelo base: [`dccuchile/bert-base-spanish-wwm-cased`](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased)
- Entrenado con `transformers.Trainer`

---

## üß™ Librer√≠as necesarias

```bash
pip install numpy==1.26.4 fsspec==2023.9.2 transformers datasets evaluate accelerate bitsandbytes transformers-interpret scikit-learn


